{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2e4de5-084a-4d00-b0a9-91400678f860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/p/project/raise-ctp2/cern/particleflow/nbs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778675c8-69ff-4fc0-8df7-edf5a66d6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/p/project/raise-ctp2/cern/particleflow/mlpf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4aa0bb6-e28c-4a9f-bcbd-a582781517bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 14:53:14.130858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 14:53:27.710704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /p/software/jurecadc/stages/2022/software/OpenMPI/4.1.2-GCC-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libevent/2.1.12-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/hwloc/2.5.0-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libpciaccess/0.16-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libxml2/2.9.10-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/cuDNN/8.3.1.22-CUDA-11.5/lib:/p/software/jurecadc/stages/2022/software/CUDA/11.5/nvvm/lib64:/p/software/jurecadc/stages/2022/software/CUDA/11.5/extras/CUPTI/lib64:/p/software/jurecadc/stages/2022/software/CUDA/11.5/lib:/p/software/jurecadc/stages/2022/software/NCCL/2.15.1-1-GCCcore-11.2.0-CUDA-11.5/lib:/p/software/jurecadc/stages/2022/software/UCX/default/lib:/p/software/jurecadc/stages/2022/software/numactl/2.0.14/lib:/p/software/jurecadc/stages/2022/software/nvidia-driver/default/lib:/p/software/jurecadc/stages/2022/software/libarchive/3.5.1-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/XZ/5.2.5-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/cURL/7.78.0-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/OpenSSL/1.1/lib:/p/software/jurecadc/stages/2022/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/ncurses/6.2-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/binutils/2.37-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/zlib/1.2.11-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/GCCcore/11.2.0/lib64\n",
      "2023-04-06 14:53:27.711656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /p/software/jurecadc/stages/2022/software/OpenMPI/4.1.2-GCC-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libevent/2.1.12-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/hwloc/2.5.0-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libpciaccess/0.16-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/libxml2/2.9.10-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/cuDNN/8.3.1.22-CUDA-11.5/lib:/p/software/jurecadc/stages/2022/software/CUDA/11.5/nvvm/lib64:/p/software/jurecadc/stages/2022/software/CUDA/11.5/extras/CUPTI/lib64:/p/software/jurecadc/stages/2022/software/CUDA/11.5/lib:/p/software/jurecadc/stages/2022/software/NCCL/2.15.1-1-GCCcore-11.2.0-CUDA-11.5/lib:/p/software/jurecadc/stages/2022/software/UCX/default/lib:/p/software/jurecadc/stages/2022/software/numactl/2.0.14/lib:/p/software/jurecadc/stages/2022/software/nvidia-driver/default/lib:/p/software/jurecadc/stages/2022/software/libarchive/3.5.1-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/XZ/5.2.5-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/cURL/7.78.0-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/OpenSSL/1.1/lib:/p/software/jurecadc/stages/2022/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/ncurses/6.2-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/binutils/2.37-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/zlib/1.2.11-GCCcore-11.2.0/lib:/p/software/jurecadc/stages/2022/software/GCCcore/11.2.0/lib64\n",
      "2023-04-06 14:53:27.711665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/p/project/raise-ctp2/cern/miniconda3/envs/tf2/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "WARNING:root:horovod not found, ignoring\n",
      "WARNING:root:horovod not found, ignoring\n"
     ]
    }
   ],
   "source": [
    "# mlpf pipeline imports\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import datetime\n",
    "import glob\n",
    "import random\n",
    "import platform\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import click\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from functools import partial\n",
    "import shlex\n",
    "import subprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner as kt\n",
    "\n",
    "# from tfmodel.model_setup import (\n",
    "#     make_model,\n",
    "#     configure_model_weights,\n",
    "#     LearningRateLoggingCallback,\n",
    "#     prepare_callbacks,\n",
    "#     FlattenedCategoricalAccuracy,\n",
    "#     eval_model,\n",
    "#     freeze_model,\n",
    "# )\n",
    "\n",
    "# from tfmodel.utils import (\n",
    "#     get_lr_schedule,\n",
    "#     get_optimizer,\n",
    "#     create_experiment_dir,\n",
    "#     get_strategy,\n",
    "#     make_weight_function,\n",
    "#     load_config,\n",
    "#     compute_weights_invsqrt,\n",
    "#     compute_weights_none,\n",
    "#     get_train_val_datasets,\n",
    "#     targets_multi_output,\n",
    "#     get_dataset_def,\n",
    "#     prepare_val_data,\n",
    "#     set_config_loss,\n",
    "#     get_loss_dict,\n",
    "#     parse_config,\n",
    "#     get_best_checkpoint,\n",
    "#     delete_all_but_best_checkpoint,\n",
    "#     get_tuner,\n",
    "# )\n",
    "\n",
    "from tfmodel.lr_finder import LRFinder\n",
    "from tfmodel.callbacks import CustomTensorBoard\n",
    "from tfmodel import hypertuning\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.integration.keras import TuneReportCheckpointCallback\n",
    "from ray.tune.integration.tensorflow import DistributedTrainableCreator\n",
    "from ray.tune.logger import TBXLoggerCallback\n",
    "from ray.tune import Analysis, ExperimentAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e4f785-2118-46fe-9cd1-0bd5723a1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e66ec74-578c-441f-8880-5ed53ab402a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc_file\n",
    "rc_file(\"my_matplotlib_rcparams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4192f-1bb5-451a-87ee-93c46d4632de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_results_folder = \"/p/project/raise-ctp2/cern/ray_results/\"  # Main folder containing all ray experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab034db2-4930-4983-bade-eeb3f5c6b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2240\n",
      "drwxr-sr-x 1840 wulff1 524288 Feb 20 09:50 \u001b[0m\u001b[01;34masha_scikit_samples400\u001b[0m/\n",
      "drwxr-sr-x   11 wulff1  16384 Feb 16 16:18 \u001b[01;34mclic_gnn_scan\u001b[0m/\n",
      "drwxr-sr-x    8 wulff1  16384 Feb 16 20:31 \u001b[01;34mclic_transformer_bs_scan\u001b[0m/\n",
      "drwxr-sr-x   11 wulff1  16384 Feb 15 16:38 \u001b[01;34mclic_transformer_scan\u001b[0m/\n",
      "drwxr-sr-x  458 wulff1 131072 Apr  4 12:35 \u001b[01;34mclic_transformer_search_asha_hyperopt_n500\u001b[0m/\n",
      "drwxr-sr-x  502 wulff1 131072 Mar  1 13:36 \u001b[01;34mclic_transformer_search_asha_n500\u001b[0m/\n",
      "drwxr-sr-x  234 wulff1  65536 Jun  1  2022 \u001b[01;34mcmsgen_asha_epochs100\u001b[0m/\n",
      "drwxr-sr-x  202 wulff1  65536 Jun  7  2022 \u001b[01;34mcmsgen_asha_epochs50\u001b[0m/\n",
      "drwxr-sr-x  471 wulff1 131072 Aug  3  2022 \u001b[01;34mdelphes_svr_dataset\u001b[0m/\n",
      "drwxr-sr-x   22 wulff1  16384 Sep 21  2022 \u001b[01;34mevent_loss_scan\u001b[0m/\n",
      "drwxr-sr-x   26 wulff1  16384 Sep 22  2022 \u001b[01;34mevent_loss_scan6\u001b[0m/\n",
      "drwxrwxrwx  112 wulff1  16384 May 29  2022 \u001b[34;42mtune_result_dir\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ll $ray_results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abed3235-806f-4344-a223-d8d7f3d9fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which experiments to analyze\n",
    "exp_dir_list = [# ray_results_folder + \"cmsgen_asha_epochs50\",\n",
    "                # ray_results_folder + \"cmsgen_asha_epochs100\",\n",
    "                # ray_results_folder + \"cmsgen_asha_scikit_epochs50_samples400_OneGPUPerTrial\",\n",
    "                # ray_results_folder + \"cmsgen_asha_scikit_epochs50_samples200_FourGPUPerTrial\",\n",
    "                # ray_results_folder + \"clic_transformer_search_asha_n500\",\n",
    "                ray_results_folder + \"clic_transformer_search_asha_hyperopt_n500\",\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda4ef08-29d9-425c-9036-dcbf291468a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mode = \"min\"\n",
    "default_metric = \"val_loss\"\n",
    "expanalysis_list = []\n",
    "for exp_dir in exp_dir_list:\n",
    "    expanalysis_list.append(ExperimentAnalysis(exp_dir, default_metric=default_metric, default_mode=default_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea11aa8a-ea1f-4990-99e7-1997337212c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_get_df(analysis):\n",
    "    try:\n",
    "        result_df = analysis.dataframe()\n",
    "    except IndexError:\n",
    "        result_df = analysis.results_df.dropna(axis=0, how=\"all\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97015e7e-814d-4473-b82f-9be79c7225db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time from start to timestamp:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ray.tune.analysis.experiment_analysis:Couldn't read config from 94 paths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98 h /p/project/raise-ctp2/cern/ray_results/clic_transformer_search_asha_hyperopt_n500\n"
     ]
    }
   ],
   "source": [
    "print(\"Time from start to timestamp:\")\n",
    "for expanalysis in expanalysis_list:\n",
    "    res_df = robust_get_df(expanalysis)\n",
    "    exp_dir = Path(res_df['logdir'][0]).parent\n",
    "    stats = expanalysis.stats() \n",
    "    print(\"{:.2f}\".format((stats[\"timestamp\"] - stats[\"start_time\"]) / 60 / 60), \"h\", exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89482359-f266-45b9-83f5-2d32f7c4a50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['charge_loss', 'cls_loss', 'cos_phi_loss', 'energy_loss', 'eta_loss',\n",
       "       'learning_rate', 'loss', 'pt_loss', 'sin_phi_loss', 'val_charge_loss',\n",
       "       'val_cls_loss', 'val_cos_phi_loss', 'val_energy_loss', 'val_eta_loss',\n",
       "       'val_loss', 'val_pt_loss', 'val_sin_phi_loss', 'val_jet_wd',\n",
       "       'val_jet_iqr', 'val_jet_med', 'val_met_wd', 'val_met_iqr',\n",
       "       'val_met_med', 'time_this_iter_s', 'should_checkpoint', 'done',\n",
       "       'timesteps_total', 'episodes_total', 'training_iteration', 'trial_id',\n",
       "       'experiment_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname',\n",
       "       'node_ip', 'time_since_restore', 'timesteps_since_restore',\n",
       "       'iterations_since_restore', 'warmup_time', 'config/batch_multiplier',\n",
       "       'config/hidden_dim', 'config/lr', 'config/num_heads',\n",
       "       'config/num_layers_decoder_cls', 'config/num_layers_decoder_reg',\n",
       "       'config/num_layers_encoder', 'config/num_random_features',\n",
       "       'config/out_hidden_dim', 'config/out_num_layers', 'logdir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d961e925-4d3e-40d9-889c-e1218e96d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_best_results(expanalysis_list):\n",
    "    summ = []\n",
    "    for expanalysis in expanalysis_list:\n",
    "        res_df = robust_get_df(expanalysis)\n",
    "        exp_dir = Path(res_df['logdir'][0]).parent\n",
    "\n",
    "        dd = expanalysis.best_result\n",
    "        val_reg_loss = sum([dd[\"val_{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]])\n",
    "        reg_loss = sum([dd[\"{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]])\n",
    "\n",
    "        conf = expanalysis.best_result.pop(\"config\")\n",
    "\n",
    "        expanalysis.best_result.update({\"val_reg_loss\": val_reg_loss, \"reg_loss\": reg_loss})\n",
    "        expanalysis.best_result.update({x: conf[x] for x in conf})\n",
    "\n",
    "        summ.append(pd.DataFrame(expanalysis.best_result, index=[exp_dir]))\n",
    "        expanalysis.best_result.update({\"config\": conf})\n",
    "    return pd.concat(summ)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ae5c09b-e1f7-43ba-9fbd-dccb7033cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ray.tune.analysis.experiment_analysis:Couldn't read config from 94 paths\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_best_results(expanalysis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f624e2d-9d28-4665-a62c-5f522a2efc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>/p/project/raise-ctp2/cern/ray_results/clic_transformer_search_asha_hyperopt_n500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>7.921819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>7.834934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_loss</th>\n",
       "      <td>0.050746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_cls_loss</th>\n",
       "      <td>0.049924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_loss</th>\n",
       "      <td>0.390448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_reg_loss</th>\n",
       "      <td>0.389944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_multiplier</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers_encoder</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers_decoder_reg</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers_decoder_cls</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_dim</th>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_heads</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_random_features</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_hidden_dim</th>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_num_layers</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        /p/project/raise-ctp2/cern/ray_results/clic_transformer_search_asha_hyperopt_n500\n",
       "loss                                                             7.921819                                \n",
       "val_loss                                                         7.834934                                \n",
       "cls_loss                                                         0.050746                                \n",
       "val_cls_loss                                                     0.049924                                \n",
       "reg_loss                                                         0.390448                                \n",
       "val_reg_loss                                                     0.389944                                \n",
       "lr                                                               0.000100                                \n",
       "batch_multiplier                                                10.000000                                \n",
       "num_layers_encoder                                               1.000000                                \n",
       "num_layers_decoder_reg                                           4.000000                                \n",
       "num_layers_decoder_cls                                           3.000000                                \n",
       "hidden_dim                                                     256.000000                                \n",
       "num_heads                                                        8.000000                                \n",
       "num_random_features                                             16.000000                                \n",
       "out_hidden_dim                                                 256.000000                                \n",
       "out_num_layers                                                   3.000000                                "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting = [\"loss\", \"val_loss\",\n",
    "               \"cls_loss\", \"val_cls_loss\",\n",
    "               \"reg_loss\", \"val_reg_loss\",\n",
    "               # 'cls_acc_unweighted', 'val_cls_acc_weighted',\n",
    "               # 'cls_acc_unweighted', 'val_cls_acc_unweighted',\n",
    "              ]\n",
    "interesting += [x for x in expanalysis.best_result[\"config\"].keys()]\n",
    "summary.sort_values(default_metric)\n",
    "summary[interesting].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357e0f8-6226-4e66-be7c-0ddf629ac106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_ray112",
   "language": "python",
   "name": "tf2_ray112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
