{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dirs = [\n",
    "#     \"/p/project/raise-ctp2/cern/particleflow/experiments/\"\n",
    "#              ]\n",
    "\n",
    "train_dirs = list(Path(\"/p/project/raise-ctp2/cern/particleflow/experiments/\").glob(\"before_raytune_with_jet_met_logs_*\"))\n",
    "info_string = \"Before hypertuning\"\n",
    "\n",
    "print(\"Length of train_dirs:\", len(train_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = train_dirs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_history(hist_dir, verbose=False):\n",
    "    jsons = list(hist_dir.glob(\"history*.json\"))\n",
    "    if verbose:\n",
    "        print(f\"{hist_dir.parent} has {len(jsons)} hisotries\")\n",
    "    jsons.sort(key=lambda x: int(x.name.split(\"_\")[1].split(\".\")[0]))  # sort according to epoch number\n",
    "\n",
    "    # initialize a dict with correct keys and empty lists as values\n",
    "    with open(jsons[0]) as h:\n",
    "        keys = json.load(h).keys()\n",
    "    full_history = {key: [] for key in keys}\n",
    "\n",
    "    # join epoch values to a full history\n",
    "    for path in jsons:\n",
    "        with open(path) as h:\n",
    "            epoch = json.load(h)\n",
    "            for key in epoch.keys():\n",
    "                full_history[key].append(epoch[key])\n",
    "\n",
    "    reg_loss = np.sum(\n",
    "        np.array([full_history[\"{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]),\n",
    "        axis=0,\n",
    "    )\n",
    "    val_reg_loss = np.sum(\n",
    "        np.array(\n",
    "            [full_history[\"val_{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    full_history.update({\"reg_loss\": reg_loss})\n",
    "    full_history.update({\"val_reg_loss\": val_reg_loss})\n",
    "\n",
    "    return full_history, len(jsons)\n",
    "\n",
    "\n",
    "def get_histories(train_dirs):\n",
    "    train_dirs = [Path(train_dir) for train_dir in train_dirs]\n",
    "    histories = []\n",
    "\n",
    "    for train_dir in train_dirs:\n",
    "        hist, N = get_full_history(hist_dir=train_dir / \"logs/history\")\n",
    "        histories.append(hist)\n",
    "\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = get_histories(train_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def cms_label(x0=0.12, x1=0.23, x2=0.67, y=0.90):\n",
    "#     plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=16)\n",
    "#     plt.figtext(x1, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=14)\n",
    "#     plt.figtext(x2, y,r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, QCD with PU50',  wrap=False, horizontalalignment='left', fontsize=12)\n",
    "\n",
    "def cms_label(x0=0.12, y=0.90, s=None, fz=22):\n",
    "    plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=fz)\n",
    "    plt.figtext(x0+0.09, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=fz-3)\n",
    "    if s is not None:\n",
    "        t = plt.figtext(x=x0, y=y-0.15, s=s[:-1], fontsize=fz-6)\n",
    "#         t.set_bbox(dict(facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# def run_label(x=0.67, y=0.90, fz=12):\n",
    "#     plt.figtext(x, y,r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, QCD with PU50',  wrap=False, horizontalalignment='left', fontsize=fz)\n",
    "\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=22):\n",
    "    plt.figtext(x, y,r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, $\\mathrm{z}\\tau\\tau$, QCD, QCD with high $p_T$, PU 55-75',  wrap=False, horizontalalignment='left', fontsize=fz)\n",
    "\n",
    "\n",
    "def get_combined_array(key):\n",
    "    combined_array = np.array(histories[0][key])\n",
    "    for ii in range(1, len(histories)):\n",
    "        combined_array = np.vstack([combined_array, np.array(histories[ii][key])])\n",
    "    return combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_histories = []\n",
    "for history in histories:\n",
    "    if len(history['loss']) == 100:\n",
    "        finished_histories.append(history)\n",
    "histories = finished_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = get_combined_array(\"loss\")\n",
    "reg_loss_array = get_combined_array(\"reg_loss\")\n",
    "cls_loss_array = get_combined_array(\"cls_loss\")\n",
    "\n",
    "val_loss_array = get_combined_array(\"val_loss\")\n",
    "val_reg_loss_array = get_combined_array(\"val_reg_loss\")\n",
    "val_cls_loss_array = get_combined_array(\"val_cls_loss\")\n",
    "\n",
    "cls_acc_weighted_array = get_combined_array(\"cls_acc_weighted\")\n",
    "val_cls_acc_weighted_array = get_combined_array(\"val_cls_acc_weighted\")\n",
    "\n",
    "val_met_wd_array = get_combined_array(\"val_met_wd\")\n",
    "val_jet_wd_array = get_combined_array(\"val_jet_wd\")\n",
    "val_met_iqr_array = get_combined_array(\"val_met_iqr\")\n",
    "val_jet_iqr_array = get_combined_array(\"val_jet_iqr\")\n",
    "val_met_med_array = get_combined_array(\"val_met_med\")\n",
    "val_jet_med_array = get_combined_array(\"val_jet_med\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.shape, val_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance_curve(array_list,\n",
    "                        labels,\n",
    "                        skip=0,\n",
    "                        ylim=None,\n",
    "                        save_path=None,\n",
    "                        x=0.45,\n",
    "                        y=0.53,\n",
    "                        loc=None,\n",
    "                        ylabel=None,\n",
    "                        custom_info=None,\n",
    "                       ):\n",
    "    fig = plt.figure()\n",
    "    final_means = []\n",
    "    final_stds = []\n",
    "    for ii, array in enumerate(array_list):\n",
    "        xx = np.array(range(array.shape[1])) + 1  # Epochs\n",
    "\n",
    "        xx = xx[skip:]\n",
    "        array = array[:, skip:]\n",
    "\n",
    "        std = np.std(array, axis=0)\n",
    "        mean = np.mean(array, axis=0)\n",
    "\n",
    "        plt.plot(xx, mean, label=labels[ii])\n",
    "        plt.fill_between(xx, mean - std, mean + std, alpha=0.4)\n",
    "\n",
    "        # Add individual loss curves\n",
    "        # plt.plot(np.tile(xx, reps=[10,1]).transpose(), array.transpose(), linewidth=0.2)\n",
    "\n",
    "        print(labels[ii] + \": {:.4f} +/- {:#.2g}\".format(mean[-1], std[-1]))\n",
    "        final_means.append(mean[-1])\n",
    "        final_stds.append(std[-1])\n",
    "\n",
    "#     plt.legend(bbox_to_anchor=(0.98, 0.78), loc=\"center right\")\n",
    "    if loc is not None:\n",
    "        plt.legend(loc=loc)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    s=\"{:s}\\nMean and standard deviation of {:d} trainings\\n\".format(info_string, array.shape[0])\n",
    "    for ii, label in enumerate(labels):\n",
    "        if custom_info:\n",
    "            s += \"Final {}: {} +/- {}\\n\".format(label.lower(), custom_info[ii]['mean'], custom_info[ii][\"std\"])\n",
    "        else:\n",
    "            s += \"Final {}: {:.3f} +/- {:#.2g}\\n\".format(label.lower(), final_means[ii], final_stds[ii])\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[1], bottom=ylim[0])\n",
    "\n",
    "    cms_label(x0=x, y=y, s=s, fz=26)\n",
    "    run_label(x=0.12, y=0.89, fz=24)\n",
    "    if save_path:\n",
    "        plt.savefig(Path(save_path).with_suffix('.png'))\n",
    "        plt.savefig(Path(save_path).with_suffix('.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file(\"my_matplotlib_rcparams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axes\n",
    "mpl.rcParams[\"axes.titlesize\"] = 20\n",
    "mpl.rcParams[\"axes.labelsize\"] = 30\n",
    "\n",
    "# Ticks\n",
    "mpl.rcParams[\"xtick.labelsize\"] = 25\n",
    "mpl.rcParams[\"ytick.labelsize\"] = 25\n",
    "mpl.rcParams[\"xtick.direction\"] = \"in\"\n",
    "mpl.rcParams[\"ytick.direction\"] = \"in\"\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams[\"legend.fontsize\"] = 24\n",
    "\n",
    "mpl.rcParams[\"grid.alpha\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([loss_array, val_loss_array],\n",
    "                    labels=[\"Training loss\", \"Validation loss\"],\n",
    "                    skip=10,\n",
    "                    # ylim=[0.5, 2.5],\n",
    "                    save_path=\"loss_curves_std_after_tuning.png\",\n",
    "                    x=0.37,\n",
    "                    y=0.68,\n",
    "                    ylabel=\"Loss\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([cls_acc_weighted_array, val_cls_acc_weighted_array],\n",
    "                    [\"Train accuracy\", \"Valididation accuracy\"],\n",
    "                    skip=10,\n",
    "                    # ylim=(0.7, 0.9),\n",
    "                    save_path=\"cls_acc_std_after_tuning.png\",\n",
    "                    x=0.37,\n",
    "                    y=0.48,\n",
    "                    loc=\"lower right\",\n",
    "                    ylabel=\"Accuracy\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([reg_loss_array, val_reg_loss_array],\n",
    "                    labels=[\"Training regression loss\", \"Validation regression loss\"],\n",
    "                    skip=10,\n",
    "                    # ylim=(0.0, 0.2),\n",
    "                    ylabel=\"Regression loss\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([val_jet_wd_array, val_met_wd_array],\n",
    "                    labels=[\"Jet Wasserstein distance\", \"MET Wasserstein distances\"],\n",
    "                    skip=0,\n",
    "                    # ylim=(0.0, 0.2),\n",
    "                    ylabel=\"Jet and MET Wasserstein distance\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([cls_loss_array, val_cls_loss_array],\n",
    "                    labels=[\"Training classification loss\", \"Validation classification loss\"],\n",
    "                    skip=10,\n",
    "#                     ylim=(0.0, 0.005),\n",
    "                    ylabel=\"Classification loss\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_ray112",
   "language": "python",
   "name": "tf2_ray112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
