{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "from uncertainties import ufloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_histories, get_full_history, get_combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FZJ #####\n",
    "train_dirs = list(Path(\"/p/project/raise-ctp2/cern/particleflow/experiments/\")\n",
    "                  .glob(\"before_raytune_with_jet_met_logs_*\"))\n",
    "info_string = \"Before HPO\"\n",
    "###############\n",
    "\n",
    "##### Flatiron #####\n",
    "train_dirs = list(Path(\"/mnt/ceph/users/ewulff/particleflow/experiments/\")\n",
    "                  .glob(\"clic_gnn_beforeHPO*\"))\n",
    "info_string = \"Before HPO\"\n",
    "###############\n",
    "\n",
    "print(\"Length of train_dirs:\", len(train_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = get_histories(train_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shortest_history(histories):\n",
    "    if len(histories) == 0:\n",
    "        raise ValueError(\"Given history list is empty list\")\n",
    "    shortest = 1000000\n",
    "    for history in histories:\n",
    "        l = len(history['loss'])\n",
    "        if l < shortest:\n",
    "            shortest = l\n",
    "    return shortest\n",
    "\n",
    "find_shortest_history(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in histories:\n",
    "    print(len(history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['loss', 'reg_loss', 'cls_loss', 'val_loss', 'val_reg_loss', 'val_cls_loss',\n",
    "           # 'cls_acc_weighted', 'val_cls_acc_weighted', \n",
    "           'val_met_wd', 'val_jet_wd', 'val_met_iqr', 'val_jet_iqr', 'val_met_med', 'val_jet_med'\n",
    "          ]\n",
    "\n",
    "# shortest = find_shortest_history(histories)\n",
    "# for history in histories:\n",
    "#     for metric in metrics:\n",
    "#         history[metric] = history[metric][:shortest]\n",
    "\n",
    "finished_histories = []\n",
    "for history in histories:\n",
    "    if len(history['loss']) == 150:\n",
    "        finished_histories.append(history)\n",
    "histories = finished_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = get_combined_array(histories, \"loss\")\n",
    "reg_loss_array = get_combined_array(histories,\"reg_loss\")\n",
    "cls_loss_array = get_combined_array(histories,\"cls_loss\")\n",
    "\n",
    "val_loss_array = get_combined_array(histories,\"val_loss\")\n",
    "val_reg_loss_array = get_combined_array(histories,\"val_reg_loss\")\n",
    "val_cls_loss_array = get_combined_array(histories,\"val_cls_loss\")\n",
    "\n",
    "# cls_acc_weighted_array = get_combined_array(\"cls_acc_weighted\")\n",
    "# val_cls_acc_weighted_array = get_combined_array(\"val_cls_acc_weighted\")\n",
    "\n",
    "val_met_wd_array = get_combined_array(histories,\"val_met_wd\")\n",
    "val_jet_wd_array = get_combined_array(histories,\"val_jet_wd\")\n",
    "val_met_iqr_array = get_combined_array(histories,\"val_met_iqr\")\n",
    "val_jet_iqr_array = get_combined_array(histories,\"val_jet_iqr\")\n",
    "val_met_med_array = get_combined_array(histories,\"val_met_med\")\n",
    "val_jet_med_array = get_combined_array(histories,\"val_jet_med\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.shape, val_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigdigits(mean, std):\n",
    "    return \"{:.2u}\".format(ufloat(mean, std))\n",
    "\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=12):\n",
    "    plt.figtext(x, y, r'GNN-based model, cluster-based CLIC dataset v1.3.0, $\\mathrm{t}\\overline{\\mathrm{t}}$, qq',  wrap=False, horizontalalignment='right', fontsize=fz)\n",
    "\n",
    "\n",
    "def cms_label(x0=0.12, y=0.90, s=None, fz=22):\n",
    "    # plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=fz)\n",
    "    # plt.figtext(x0+0.09, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=fz-3)\n",
    "    if s is not None:\n",
    "        t = plt.figtext(x=x0, y=y-0.15, s=s[:-1], fontsize=fz-6)\n",
    "\n",
    "\n",
    "def plot_variance_curve(array_list,\n",
    "                        labels,\n",
    "                        skip=0,\n",
    "                        ylim=None,\n",
    "                        save_path=None,\n",
    "                        x=0.45,\n",
    "                        y=0.53,\n",
    "                        loc=None,\n",
    "                        ylabel=None,\n",
    "                        custom_info=None,\n",
    "                       ):\n",
    "    fig = plt.figure()\n",
    "    final_means = []\n",
    "    final_stds = []\n",
    "    for ii, array in enumerate(array_list):\n",
    "        print(f\"{labels[ii]} is averaged over {array.shape[0]} trainings.\")\n",
    "        xx = np.array(range(array.shape[1])) + 1  # Epochs\n",
    "\n",
    "        xx = xx[skip:]\n",
    "        array = array[:, skip:]\n",
    "\n",
    "        std = np.std(array, axis=0)\n",
    "        mean = np.mean(array, axis=0)\n",
    "\n",
    "        plt.plot(xx, mean, label=labels[ii])\n",
    "        plt.fill_between(xx, mean - std, mean + std, alpha=0.4)\n",
    "\n",
    "        # Add individual loss curves\n",
    "        # plt.plot(np.tile(xx, reps=[10,1]).transpose(), array.transpose(), linewidth=0.2)\n",
    "\n",
    "        print(labels[ii] + \": {:s}\".format(sigdigits(mean[-1], std[-1])))\n",
    "        final_means.append(mean[-1])\n",
    "        final_stds.append(std[-1])\n",
    "\n",
    "#     plt.legend(bbox_to_anchor=(0.98, 0.78), loc=\"center right\")\n",
    "    if loc is not None:\n",
    "        plt.legend(loc=loc)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    s=\"{:s}\\nMean and standard deviation of {:d} trainings\\n\".format(info_string, array.shape[0])\n",
    "    for ii, label in enumerate(labels):\n",
    "        if custom_info:\n",
    "            s += \"Final {}: {:s}\\n\".format(label.lower(), sigdigits(custom_info[ii]['mean'], custom_info[ii][\"std\"]))\n",
    "        else:\n",
    "            s += \"Final {}: {:s}\\n\".format(label.lower(), sigdigits(final_means[ii], final_stds[ii]))\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[1], bottom=ylim[0])\n",
    "\n",
    "    plt.subplots_adjust(left=0.14)\n",
    "        \n",
    "    cms_label(x0=x, y=y, s=s, fz=24)\n",
    "    run_label(x=0.9, y=0.89, fz=22)\n",
    "    if save_path:\n",
    "        plt.savefig(Path(save_path).with_suffix('.png'))\n",
    "        plt.savefig(Path(save_path).with_suffix('.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file(\"my_matplotlib_rcparams.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axes\n",
    "mpl.rcParams[\"axes.labelsize\"] = 24\n",
    "\n",
    "# Ticks\n",
    "mpl.rcParams[\"xtick.labelsize\"] = 22\n",
    "mpl.rcParams[\"ytick.labelsize\"] = 22\n",
    "mpl.rcParams[\"xtick.direction\"] = \"in\"\n",
    "mpl.rcParams[\"ytick.direction\"] = \"in\"\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams[\"legend.fontsize\"] = 24\n",
    "\n",
    "mpl.rcParams[\"grid.alpha\"] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([loss_array, val_loss_array],\n",
    "                    labels=[\"Training loss\", \"Validation loss\"],\n",
    "                    skip=10,\n",
    "                    ylim=[5, 12],\n",
    "                    save_path=\"std_plots/beforeHPO_gnn_loss_curves_std_after_tuning.png\",\n",
    "                    x=0.4,\n",
    "                    y=0.4,\n",
    "                    ylabel=\"Loss (a.u.)\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([reg_loss_array, val_reg_loss_array],\n",
    "                    labels=[\"Training regression loss\", \"Validation regression loss\"],\n",
    "                    skip=10,\n",
    "                    save_path=\"std_plots/beforeHPO_gnn_reg_loss_curves_std_after_tuning.png\",\n",
    "                    x=0.39,\n",
    "                    y=0.4,\n",
    "                    ylim=(0.19, 0.55),\n",
    "                    ylabel=\"Regression loss (a.u.)\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([val_jet_wd_array, val_met_wd_array],\n",
    "                    labels=[\"Jet Wasserstein distance\", \"MET Wasserstein distances\"],\n",
    "                    skip=4,\n",
    "                    save_path=\"std_plots/beforeHPO_gnn_wd_curves_std_after_tuning.png\",\n",
    "                    x=0.39,\n",
    "                    y=0.3,\n",
    "                    ylim=(-1, 5),\n",
    "                    ylabel=\"Jet & MET Wasserstein distance (a.u.)\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([cls_loss_array, val_cls_loss_array],\n",
    "                    labels=[\"Training classification loss\", \"Validation classification loss\"],\n",
    "                    skip=10,\n",
    "                    save_path=\"std_plots/beforeHPO_gnn_cls_loss_curves_std_after_tuning.png\",\n",
    "                    x=0.33,\n",
    "                    y=0.4,\n",
    "                    ylim=(0.034, 0.075),\n",
    "                    ylabel=\"Classification loss (a.u.)\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
