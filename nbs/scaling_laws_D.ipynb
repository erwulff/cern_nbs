{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43eb0166-2f08-4597-b8e3-a622ec5b0812",
   "metadata": {},
   "source": [
    "# Scaling laws for neural particle flow reconstruction in 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc417d-9237-4fe6-b372-705749c5c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379376a-c0ef-49fb-8427-ce9d140a33e3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7778f36-bd47-4a90-93a8-c76b9b2bea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6f408a8-2ff1-4b33-b598-378c5f81f4d6",
   "metadata": {},
   "source": [
    "mlpf_path = \"/mnt/ceph/users/ewulff/particleflow/mlpf\"\n",
    "sys.path.append(mlpf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc055358-c2c8-4bc5-8378-e91ef8d04e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import ExperimentAnalysis, ResultGrid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc_file\n",
    "import pandas as pd\n",
    "from matplotlib import rc_file\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b57be-aeeb-4bce-8b9c-1b6c47d307f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_skipped_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927858e-8a0b-41df-9309-97fc107d8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FZJ #####\n",
    "# ray_results_folder = \"/p/project/raise-ctp2/cern/ray_results/\"  # Main folder containing all ray experiments\n",
    "\n",
    "##### Flatiron #####\n",
    "ray_results_folder = \"/mnt/ceph/users/ewulff/ray_results/\"  # Main folder containing all ray experiments\n",
    "exp_dir = ray_results_folder + \"test_raytune_Dscan_v2/\"\n",
    "####################\n",
    "count_skipped_configurations(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347ebec-916b-4baf-9460-bb0ef5275f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExperimentAnalysis is how Ray used to organize results\n",
    "expanalysis = ExperimentAnalysis(exp_dir, default_metric=\"val_loss\", default_mode=\"min\")\n",
    "\n",
    "# ResultGrid is the new way Ray organizes results\n",
    "resultgrid = ResultGrid(expanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c67b0f-3284-410c-abae-b1b137453aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rg_df = resultgrid.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f8d73-d4ff-4d59-bb4d-0ab763918888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add path and parameter counts to resultgrid dataframe\n",
    "\n",
    "# get column names from a result (using the best because it's easy to get out of resultgrid)\n",
    "column_names = pd.read_csv(resultgrid.get_best_result().path + '/params.csv').columns\n",
    "params_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "trial_id_list = []\n",
    "path_list = []\n",
    "\n",
    "for i, result in enumerate(resultgrid):\n",
    "    trial_id_list.append(result.metrics[\"trial_id\"])\n",
    "    path_list.append(result.path)\n",
    "    df = pd.read_csv(result.path + '/params.csv')\n",
    "    df[\"trial_id\"] = result.metrics[\"trial_id\"]\n",
    "    params_df = pd.concat([params_df, df], ignore_index=True)\n",
    "\n",
    "path_df = pd.DataFrame({\"trial_id\": trial_id_list, \"path\": path_list})\n",
    "\n",
    "# sort dataframes according to trial_dir to make sure we add the paths in correct order\n",
    "path_df.sort_values(\"trial_id\", inplace=True)\n",
    "rg_df.sort_values(\"trial_id\", inplace=True)\n",
    "params_df.sort_values(\"trial_id\", inplace=True)\n",
    "\n",
    "rg_df[\"path\"] = path_df[\"path\"]\n",
    "rg_df[[\"total_params\", \"trainable_params\", \"nontrainable_params\"]] = params_df[[\"total_params\", \"trainable_params\", \"nontrainable_params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052e736-10af-462d-b135-f0ef9f1cdac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: implement merging of resultgrid dataframes from several Ray Tune runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d4063-d352-439f-86b8-7b3dbde85821",
   "metadata": {},
   "source": [
    "## Scaling Law study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca89b126-a99a-48b9-a4bd-e71221d0578c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axs = rg_df.plot(y=\"val_loss\", x=\"config/train_loop_config/ntrain\")\n",
    "axs.set_ylabel(\"Validation loss\")\n",
    "axs.set_xlabel(\"Training samples\")\n",
    "axs.set_xscale(\"log\")\n",
    "axs.set_yscale(\"log\")\n",
    "# axs.grid(True, axis=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91c2f1-1a66-4099-8c1f-72b1cbbc88eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OLD CODE\n",
    "## HPO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9f6e4-2e94-47a3-a4ed-858112ca3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = expanalysis.results_df\n",
    "result_df = rg_df\n",
    "# result_df = expanalysis.results_df.dropna(axis=0, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f3245-22f3-4a62-845c-953c514a059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hp_df(result_df):\n",
    "    return result_df.filter(regex=\"config/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee5657-58b3-41ed-aa25-96d4905b580b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_df = get_hp_df(result_df)\n",
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8b9d1-74e3-4da3-9e98-cc25194ab51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_df(analysis, k):\n",
    "    try:\n",
    "        if isinstance(analysis, tune.result_grid.ResultGrid):\n",
    "            result_df = analysis.get_dataframe()\n",
    "        else:\n",
    "            result_df = analysis.dataframe()\n",
    "    except IndexError:\n",
    "        result_df = analysis.results_df.dropna(axis=0, how=\"all\")\n",
    "    if isinstance(analysis, tune.result_grid.ResultGrid):\n",
    "        dd = result_df.nsmallest(k, \"val_loss\")  \n",
    "    elif analysis.default_mode == 'min':\n",
    "        dd = result_df.nsmallest(k, analysis.default_metric)\n",
    "    elif analysis.default_mode == 'max':\n",
    "        dd = result_df.nlargest(k, analysis.default_metric)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce31ce-a5e0-428e-95f5-f473dcc979ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars2titles = {\n",
    "    'val_loss': 'Validation loss (a.u.)',\n",
    "    'val_cls_loss': 'Validation classification loss (a.u.)',\n",
    "    'val_reg_loss': 'Validation regression loss (a.u.)',\n",
    "    'val_charge_loss': 'Validation charge loss (a.u.)',\n",
    "    'val_cls_acc_weighted': 'Validation classification accuracy',\n",
    "    'val_jet_wd': 'Jet Wasserstein distance (a.u.)',\n",
    "    'val_met_wd': 'MET Wasserstein distance (a.u.)',\n",
    "}\n",
    "\n",
    "\n",
    "def trial_id2logdir(trial_id, trial_dfs, verbose=True):\n",
    "    for logdir in trial_dfs.keys():\n",
    "        curr = trial_dfs[logdir]\n",
    "        if \"trial_id\" in curr.keys():\n",
    "            if curr[\"trial_id\"][0] == trial_id:\n",
    "                return logdir\n",
    "        elif verbose:\n",
    "            print(f\"WARNING: no trial id in {logdir}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=12):\n",
    "#    plt.figtext(x, y, r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, QCD with PU50; $\\mu, \\pi, \\pi_0, \\tau, \\gamma$, single particle guns',  wrap=False, horizontalalignment='left', fontsize=fz)\n",
    "    plt.figtext(x, y, r'CLIC cluster-based dataset v1.3.0, $\\mathrm{t}\\overline{\\mathrm{t}}$, qq',  wrap=False, horizontalalignment='left', fontsize=fz)\n",
    "\n",
    "\n",
    "def topk_summary_plot_v2(analysis, k, save=False, save_dir=None, skip=0, last=None, ylim=None, supress_labels=False, figsize=(12,11)):\n",
    "    to_plot = [\n",
    "        'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_charge_loss', # 'val_jet_wd', 'val_met_wd',\n",
    "    ]\n",
    "\n",
    "    dd = get_top_k_df(analysis, k)\n",
    "    dfs = analysis.trial_dataframes\n",
    "\n",
    "    fig, axs = plt.subplots(len(to_plot), 1, figsize=figsize, tight_layout=False, sharex=True)\n",
    "    plt.tight_layout(rect=[0.05, 0.02, 0.9, 1.0])\n",
    "    for irow, (var, ax_row) in enumerate(zip(to_plot, axs)):\n",
    "        i_plot = 1\n",
    "        if \"logdir\" in dd.keys():\n",
    "            iterator = enumerate(dd[\"logdir\"])\n",
    "        else:\n",
    "            iterator = enumerate(dd.index)\n",
    "        for ii, key in iterator:\n",
    "            if not \"logdir\" in dd.keys():\n",
    "                key = trial_id2logdir(key, dfs, verbose=False)\n",
    "            # if var == 'val_reg_loss':\n",
    "            #     values = sum([dfs[key][\"val_{}_loss\".format(l)].values for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]])\n",
    "            #     values = values[skip:last]\n",
    "            # else:\n",
    "            values = dfs[key][var][skip:last]\n",
    "\n",
    "            iterations = dfs[key].index.values[skip:last]\n",
    "\n",
    "            # curve labels\n",
    "            if (irow == 0) and (not supress_labels):\n",
    "                ax_row.plot(iterations, values, alpha=0.5, label=\"#{}\".format(i_plot))\n",
    "            else:\n",
    "                ax_row.plot(iterations, values, alpha=0.5)\n",
    "\n",
    "            ax_row.set_title(vars2titles[var])\n",
    "            ax_row.grid(alpha=0.3)\n",
    "\n",
    "            if ylim:\n",
    "                ax_row.set_ylim(ylim[irow])\n",
    "            i_plot += 1\n",
    "\n",
    "    ax_row.set_xlabel(\"Epoch\")\n",
    "    fig.legend(loc=\"center right\", bbox_to_anchor=(1, 0.5), )\n",
    "    plt.figtext(0.89, 0.61, \"Top trials\", fontsize=18)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=0.8, top=0.9, wspace=None, hspace=None)\n",
    "    run_label(x=0.38, y=0.95, fz=18)\n",
    "\n",
    "    if save or save_dir:\n",
    "        if save_dir:\n",
    "            plt.savefig(str(Path(save_dir) / \"topk_summary_plot_v2.pdf\"))\n",
    "        else:\n",
    "            plt.savefig(\"topk_summary_plot_v2.pdf\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78e479-aa82-4dff-9cfe-23eabcc981fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = get_top_k_df(expanalysis, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfae905-b960-421f-8105-8956b2761b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_file(\"my_matplotlib_rcparams.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9a4ae-f788-4923-8afa-8de3ce555ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: if each model is trained on a differently sized dataset, epochs contain different numbers of training samples\n",
    "topk_summary_plot_v2(expanalysis, 16, skip=1, figsize=(12, 12), save_dir=\"plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7c3bc-554c-4d94-8a23-61cd034275f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_best_checkpoint, get_best_epoch, get_best_loss\n",
    "# best_config = expanalysis.get_best_config()\n",
    "# best_logdir = expanalysis.get_best_trial().local_path\n",
    "best_config = resultgrid.get_best_result().config\n",
    "best_logdir = resultgrid.get_best_result().path\n",
    "\n",
    "print(\"best logdir:\", best_logdir)\n",
    "print(\"best config\", best_config)\n",
    "\n",
    "# print(\"best checkpoint:\", get_best_checkpoint(best_logdir), \", type:\", type(get_best_checkpoint(best_logdir)))\n",
    "# print(\"best epoch:\", get_best_epoch(best_logdir), \", type:\", type(get_best_epoch(best_logdir)))\n",
    "# print(\"best loss:\", get_best_loss(best_logdir), \", type:\", type(get_best_loss(best_logdir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8ff4f-7dab-468f-ad24-8aa6f44b67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import showJetMet\n",
    "# showJetMet(best_logdir, save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255474a-e686-44bf-94ed-26e6162b09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_config_str(key):\n",
    "    return key.split(\"config/\")[-1]\n",
    "\n",
    "\n",
    "def style_df(df):\n",
    "    cm_green = sns.light_palette(\"green\", as_cmap=True)\n",
    "    cm_red = sns.light_palette(\"red\", as_cmap=True)\n",
    "\n",
    "#    max_is_better = ['cls_acc_unweighted', 'val_cls_acc_weighted', 'val_cls_acc_unweighted']\n",
    "    # min_is_better = ['loss', 'cls_loss', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_jet_wd', 'val_met_wd', 'val_jet_iqr', 'val_met_iqr']\n",
    "    min_is_better = ['loss', 'cls_loss', 'reg_loss', 'charge_loss', 'val_loss', 'val_cls_loss', 'val_reg_loss', 'val_charge_loss']\n",
    "\n",
    "#    max_is_better = ['val_cls_acc_weighted', 'val_cls_acc_unweighted']\n",
    "#    min_is_better = ['val_loss', 'val_cls_loss', 'val_reg_loss']\n",
    "\n",
    "    return (df.style\n",
    "#      .background_gradient(cmap=cm_green, subset=max_is_better)\n",
    "      .background_gradient(cmap=cm_red, subset=min_is_better)\n",
    "#      .highlight_max(subset=max_is_better, props='color:black; font-weight:bold; background-color:yellow;')\n",
    "      .highlight_min(subset=min_is_better, props='color:black; font-weight:bold; background-color:yellow;')\n",
    "      .set_caption('Top {} trials according to {}'.format(len(df), expanalysis.default_metric))\n",
    "      .hide_index()\n",
    "      )\n",
    "\n",
    "\n",
    "def summarize_top_k(analysis, k, save=False, save_dir=None):\n",
    "    dd = get_top_k_df(analysis, k)\n",
    "\n",
    "    # val_reg_loss = sum([dd[\"val_{}_loss\".format(l)].values for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]])\n",
    "\n",
    "    summary = pd.concat([dd[[\n",
    "                             \"loss\",\n",
    "                             \"cls_loss\",\n",
    "                             \"reg_loss\",\n",
    "                             \"charge_loss\",\n",
    "                             \"val_loss\",\n",
    "                             \"val_cls_loss\",\n",
    "                             \"val_reg_loss\",\n",
    "                             \"val_charge_loss\",\n",
    "                             ]],\n",
    "                         # pd.DataFrame({\"val_reg_loss\": val_reg_loss}, index=dd.index),\n",
    "                         # dd[[\n",
    "                             # 'val_jet_wd', 'val_met_wd',\n",
    "                             # 'val_jet_iqr', 'val_met_iqr',\n",
    "                         # ]],\n",
    "                         dd.filter(regex=(\"config/*\")),\n",
    "#                        dd[\"logdir\"],\n",
    "                        ],\n",
    "                         axis=1)\n",
    "    summary.columns = [strip_config_str(col) for col in summary.columns]\n",
    "\n",
    "    styled_summary = style_df(summary.iloc[:,:-1])\n",
    "\n",
    "    if save or save_dir:\n",
    "        if save_dir:\n",
    "            styled_summary.to_excel(str(Path(save_dir) / \"summary_table.xlsx\"), engine='openpyxl')\n",
    "        else:\n",
    "            styled_summary.to_excel(\"summary_table.xlsx\")\n",
    "    return summary, styled_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc943ace-7128-4996-bbf0-8d7c1851986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ, styled = summarize_top_k(expanalysis, 20)\n",
    "summ, styled = summarize_top_k(resultgrid, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327ef1c-5e8d-4fb2-b849-14d777ab1030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21e1c3-6905-4dcf-a520-76709b905fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f9075-ffd7-4aef-9165-6b0dbb835875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(logdir, trial_dfs, metric, skip=0, end=None, include_val=True, logdirs=None, save=False, xlim=None, ylim=None):\n",
    "    key = metric\n",
    "#    hp_df = get_hp_df(result_df)\n",
    "    plt.figure()\n",
    "\n",
    "    df = trial_dfs[logdir]\n",
    "    plt.plot(df[key][skip:end], label=\"Training\")\n",
    "    if include_val:\n",
    "        clr = plt.gca().lines[-1].get_color()  # get color of last plotted line\n",
    "        plt.plot(df[\"val_\" + key][skip:end], \"--\", color=clr, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "\n",
    "    if save:\n",
    "        print(f\"Saving figs/{metric}.pdf\")\n",
    "        plt.savefig(f\"figs/{metric}.pdf\")\n",
    "\n",
    "\n",
    "def monitor_plot(logdir, trial_dfs, skip=0, end=None, **kwargs):\n",
    "    metrics_to_plot = ['loss', 'pt_loss', 'charge_loss', 'cls_loss', 'cos_phi_loss', 'energy_loss', 'eta_loss']\n",
    "    metrics_to_plot_no_val = ['val_jet_iqr', 'val_jet_med', 'val_met_wd', 'val_met_iqr', 'val_met_med']\n",
    "\n",
    "    for metric in metrics_to_plot:\n",
    "        plot_metric(logdir, trial_dfs, metric, skip=skip, end=end, **kwargs)\n",
    "\n",
    "    for metric in metrics_to_plot_no_val:\n",
    "        plot_metric(logdir, trial_dfs, metric, include_val=False, skip=skip, end=end, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b162d-dde1-42e5-890e-1c0970d87aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dfs = expanalysis.trial_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa343410-b971-4b07-9167-5aca9544c3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "monitor_plot(best_logdir, trial_dfs, skip=50, save=False, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa35713-77ab-423d-af7a-68c89085da19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
