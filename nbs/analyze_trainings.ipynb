{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1288eb36-d8cb-4aaa-b5b3-d3800d4d43f6",
   "metadata": {},
   "source": [
    "# Analysis of different MLPF event losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218bb7b-7de6-4783-acc5-da3a5d593512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4f3c1-6028-4d74-83c5-4cee4f50eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sigfig import round"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1953e8e-7ade-4a54-aa79-e29c03b038ed",
   "metadata": {},
   "source": [
    "train_dirs = list(Path(\"/p/project/raise-ctp2/cern/particleflow/experiments/\").glob(\"event_loss_scan_*\"))\n",
    "print(\"Lenght of train_dirs:\", len(train_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760eeba-82ac-4229-8326-6a8e9e6953a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dirs = [\n",
    "    Path(\"/p/project/raise-ctp2/cern/ray_results/event_loss_scan\"),\n",
    "    Path(\"/p/project/raise-ctp2/cern/ray_results/event_loss_scan6\"),\n",
    "]\n",
    "\n",
    "trial_dirs = []\n",
    "for exp_dir in exp_dirs:\n",
    "    some_trial_dirs = list(exp_dir.glob(\"build_model_and_train_*\"))\n",
    "    trial_dirs += some_trial_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d1dad-1991-49c3-bc98-f9953da404e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of trials:\", len(trial_dirs))\n",
    "for trial_dir in trial_dirs:\n",
    "    print(trial_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca22ab4-4282-428e-b044-e10d8951ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_dir2loss_names(trial_dir):\n",
    "    # return event_loss_name, met_loss_name\n",
    "    return trial_dir.name.split(\"'\")[1], trial_dir.name.split(\"'\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666f3e5-ecc1-4fe9-b346-ecbc8a6a23c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check extraction of loss names works for all dirs\n",
    "for trial_dir in trial_dirs:\n",
    "    event_loss_name, met_loss_name = trial_dir2loss_names(trial_dir)\n",
    "    print(event_loss_name, met_loss_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041eb3-a37b-447e-a841-1372bcb8ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, trial_dir in tqdm(enumerate(trial_dirs), total=len(trial_dirs), desc=\"Copying files\"):\n",
    "\n",
    "    event_loss_name, met_loss_name = trial_dir2loss_names(trial_dir)\n",
    "\n",
    "    dest = Path(\n",
    "        f\"/p/project/raise-ctp2/cern/particleflow/event_loss_logs_and_histories_60h/{event_loss_name}_{met_loss_name}\"\n",
    "    )\n",
    "\n",
    "    # dest.mkdir(parents=True, exist_ok=True)\n",
    "    # shutil.copytree(trial_dir / \"logs\", dest / f\"logs_{count}\")\n",
    "    # shutil.copytree(trial_dir / \"history\", dest / f\"history_{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb2514-3e73-43c7-be90-b79c184a55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cms_label(x0=0.12, x1=0.23, x2=0.67, y=0.90):\n",
    "#     plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=16)\n",
    "#     plt.figtext(x1, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=14)\n",
    "#     plt.figtext(x2, y,r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, $\\mathrm{z}\\tau\\tau$, QCD with PU50, QCD with high $p_T$',  wrap=False, horizontalalignment='left', fontsize=12)\n",
    "\n",
    "\n",
    "def cms_label(x0=0.12, y=0.90, s=None, fz=30):\n",
    "    plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=fz)\n",
    "    plt.figtext(x0+0.1, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=fz-3)\n",
    "    if s is not None:\n",
    "        t = plt.figtext(x=x0, y=y-0.2, s=s[:-1], fontsize=fz-6)\n",
    "#         t.set_bbox(dict(facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=22):\n",
    "    plt.figtext(x, y,r'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$, $\\mathrm{z}\\tau\\tau$, QCD, QCD with high $p_T, PU 55-75$',  wrap=False, horizontalalignment='left', fontsize=fz)\n",
    "\n",
    "\n",
    "def get_full_history(hist_dir, verbose=False):\n",
    "    jsons = list(hist_dir.glob(\"history*.json\"))\n",
    "    if verbose:\n",
    "        print(f\"{hist_dir.parent} has {len(jsons)} hisotries\")\n",
    "    jsons.sort(key=lambda x: int(x.name.split(\"_\")[1].split(\".\")[0]))  # sort according to epoch number\n",
    "\n",
    "    # initialize a dict with correct keys and empty lists as values\n",
    "    with open(jsons[0]) as h:\n",
    "        keys = json.load(h).keys()\n",
    "    full_history = {key: [] for key in keys}\n",
    "\n",
    "    # join epoch values to a full history\n",
    "    for path in jsons:\n",
    "        with open(path) as h:\n",
    "            epoch = json.load(h)\n",
    "            for key in epoch.keys():\n",
    "                full_history[key].append(epoch[key])\n",
    "\n",
    "    reg_loss = np.sum(\n",
    "        np.array([full_history[\"{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]),\n",
    "        axis=0,\n",
    "    )\n",
    "    val_reg_loss = np.sum(\n",
    "        np.array(\n",
    "            [full_history[\"val_{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    full_history.update({\"reg_loss\": reg_loss})\n",
    "    full_history.update({\"val_reg_loss\": val_reg_loss})\n",
    "\n",
    "    return full_history, len(jsons)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea98777c-90de-4dc7-8396-f52a748aa17b",
   "metadata": {},
   "source": [
    "def get_histories(train_dirs):\n",
    "    train_dirs = [Path(train_dir) for train_dir in train_dirs]\n",
    "    histories = []\n",
    "\n",
    "    for train_dir in train_dirs:\n",
    "        hist, N = get_full_history(hist_dir=train_dir / \"history\")\n",
    "        histories.append(hist)\n",
    "\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0f636-bcb6-40d3-bb8e-c682542c6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, _ = get_full_history(trial_dirs[0] / \"logs/history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a99fc-5d21-438c-969c-b70a14a28a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(fh)  # orient=\"index\", columns=[f\"epoch {i}\" for i in range(len(fh[\"loss\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692bf44-3376-4490-a859-24f203339cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398cd48-4345-4391-bbdb-26ba822cfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_combined_array(nested_list, max_length=None):\n",
    "    combined_array = np.array(nested_list[0][:max_length])\n",
    "    for ii in range(1, len(nested_list)):\n",
    "        combined_array = np.vstack([combined_array, np.array(nested_list[ii][:max_length])])\n",
    "    return combined_array\n",
    "\n",
    "\n",
    "def get_largest_common(data):\n",
    "    largest_common = 100\n",
    "    for trial in data:\n",
    "        curr = len(trial)\n",
    "        if curr < largest_common:\n",
    "            largest_common = curr\n",
    "    return largest_common\n",
    "\n",
    "\n",
    "def plot_variance_curve(\n",
    "    data_list,\n",
    "    metric,\n",
    "    labels,\n",
    "    skip=0,\n",
    "    ylim=None,\n",
    "    save_path=None,\n",
    "    x=0.45,\n",
    "    y=0.53,\n",
    "    loc=None,\n",
    "    ylabel=None,\n",
    "    verbose=False,\n",
    "    s_xpos=0.5,\n",
    "    s_ypos=0.6,\n",
    "):\n",
    "    fig = plt.figure()\n",
    "    final_means = []\n",
    "    final_stds = []\n",
    "    for ii, data in enumerate(data_list):\n",
    "\n",
    "        data = [d[metric] for d in data]\n",
    "\n",
    "        largest_common_epoch = get_largest_common(data)\n",
    "\n",
    "        array = get_combined_array(data, max_length=largest_common_epoch)\n",
    "        xx = np.array(range(array.shape[1])) + 1  # Epochs\n",
    "\n",
    "        xx = xx[skip:]\n",
    "        array = array[:, skip:]\n",
    "\n",
    "        std = np.std(array, axis=0)\n",
    "        mean = np.mean(array, axis=0)\n",
    "\n",
    "        plt.plot(xx, mean, label=labels[ii])\n",
    "        plt.fill_between(xx, mean - std, mean + std, alpha=0.4)\n",
    "\n",
    "        if verbose:\n",
    "            print(labels[ii] + \": {}\".format(round(mean[-1], std[-1], cutoff=99)))\n",
    "        final_means.append(mean[-1])\n",
    "        final_stds.append(std[-1])\n",
    "\n",
    "    s = \"Mean and standard deviation of {} trainings\\n\".format(array.shape[0])\n",
    "    for ii, label in enumerate(labels):\n",
    "        s += \"Final {}: {}\\n\".format(label.lower(), round(final_means[ii], final_stds[ii], cutoff=99))\n",
    "\n",
    "    # t = plt.figtext(x=s_xpos, y=s_ypos, s=s[:-1], fontsize=12)\n",
    "    # t.set_bbox(dict(facecolor=\"white\", alpha=0.9, edgecolor=\"black\"))\n",
    "\n",
    "    if loc is not None:\n",
    "        plt.legend(loc=loc)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[1], bottom=ylim[0])\n",
    "\n",
    "    # cms_label(x0=0.3, y=0.65, s=s, fz=28)\n",
    "    cms_label(x0=0.135, y=0.82, s=None, fz=28)\n",
    "    run_label(x=0.16, y=0.90, fz=22)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(Path(save_path).with_suffix(\".png\"))\n",
    "        plt.savefig(Path(save_path).with_suffix(\".pdf\"))\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c5a15-4232-4886-a50a-0863229189d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_history_summary(trial_dirs):\n",
    "    # create a dict with keys and empty lists\n",
    "    summary = {key: [] for key in [f\"{trial_dir2loss_names(a)[0]}:{trial_dir2loss_names(a)[1]}\" for a in trial_dirs]}\n",
    "\n",
    "    for trial_dir in tqdm(trial_dirs, total=len(trial_dirs), desc=\"Proessing history files\"):\n",
    "        fh, _ = get_full_history(trial_dir / \"logs/history\")\n",
    "        event_loss_name, met_loss_name = trial_dir2loss_names(trial_dir)\n",
    "        key = f\"{event_loss_name}:{met_loss_name}\"\n",
    "\n",
    "        summary[key].append(fh)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a77923-2219-462c-aa7b-4eccec57b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "label_dict = {\n",
    "    \"sliced_wasserstein:none\": \"Sliced Wasserstein\",\n",
    "    \"none:none\": \"Baseline\",\n",
    "    \"gen_jet_logcosh:none\": \"Gen-jet logcosh\",\n",
    "    \"hist_2d:none\": \"2D histogram\",\n",
    "    \"none:met\": \"MET\",\n",
    "}\n",
    "\n",
    "\n",
    "def plot_metric(metric, history_summary, save_path=None, verbose=False, ylabel=None, skip=0):\n",
    "    if save_path is not None:\n",
    "        Path(save_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "    plot_variance_curve(\n",
    "        data_list=[history_summary[key] for key in history_summary.keys()],\n",
    "        metric=metric,\n",
    "        labels=[label_dict[key] for key in history_summary.keys()],\n",
    "        ylabel=ylabel,\n",
    "        save_path=save_path,\n",
    "        verbose=verbose,\n",
    "        skip=skip,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bc7b2-62bb-4afb-8fe5-fafe2b1fd937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "mpl.rc_file(\"my_matplotlib_rcparams\")\n",
    "history_summary = get_history_summary(trial_dirs)\n",
    "if \"hist_2d:none\" in history_summary.keys():\n",
    "    history_summary.pop(\"hist_2d:none\")\n",
    "\n",
    "metrics_to_plot = [\n",
    "    \"val_cls_loss\",\n",
    "    \"val_reg_loss\",\n",
    "    \"val_jet_wd\",\n",
    "    \"val_jet_iqr\",\n",
    "    \"val_jet_med\",\n",
    "    \"val_met_wd\",\n",
    "    \"val_met_iqr\",\n",
    "    \"val_met_med\",\n",
    "]\n",
    "\n",
    "metric2name = {\n",
    "    \"val_cls_loss\": \"Validation classification loss\",\n",
    "    \"val_reg_loss\": \"Validation regression loss\",\n",
    "    \"val_jet_wd\": \"Validation jet Wasserstein distance\",\n",
    "    \"val_jet_iqr\": \"Validation jet IQR\",\n",
    "    \"val_jet_med\": \"Validation jet median\",\n",
    "    \"val_met_wd\": \"Validation MET Wasserstein distance\",\n",
    "    \"val_met_iqr\": \"Validation MET IQR\",\n",
    "    \"val_met_med\": \"Validation MET median\",\n",
    "}\n",
    "\n",
    "\n",
    "for metric in tqdm(metrics_to_plot, total=len(metrics_to_plot), desc=\"Plotting\"):\n",
    "    plot_metric(\n",
    "        metric,\n",
    "        history_summary,\n",
    "        save_path=Path(\"event_loss_plots\") / metric,\n",
    "        verbose=False,\n",
    "        ylabel=metric2name[metric],\n",
    "        skip=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4e05c-a378-4dac-b274-d4984e2e1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export\n",
    "\n",
    "nb_export(\"analyze_event_loss_scan.ipynb\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc4c0e-6d9b-488b-bd63-156c52a29830",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca5695-6090-485b-b82f-d4286b5ec0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat event_loss_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e160dd-bc29-4ceb-bc4a-c0685e8db583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2ac81-ff11-492c-b5e5-f77b133935a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
